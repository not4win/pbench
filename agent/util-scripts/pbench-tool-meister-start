#!/usr/bin/env python3
# -*- mode: python -*-

"""pbench-tool-meister-start

Responsible for:

   1. Starting a redis server
<<<<<<< HEAD
   2. Loading tool group data for the given tool group into the redis server
   3. Starting the tool-data-sink process
   4. Starting all the local and remote tool meisters

When complete we leave running, locally, a redis server and a tool data sink
process, and any local or remote tool meisters.

The pbench-tool-meister-stop script will take care of (gracefully) stopping
all of these processes, locally or remotely.
=======
   2. Loading up the tool group data for the target group into the redis server
   3. Starting the tool-data-sink process
   4. Starting all the local and remote tool meisters

When complete we leave running locally, a redis server and a tool data sink
process, and any local or remote tool meisters.

The pbench-tool-meister-stop will take care of (gracefully) stopping all of
these process, locally or remotely.
>>>>>>> First pass implementation of the "Tool Meister"
"""

import sys
import json
import os
<<<<<<< HEAD
import signal
=======
>>>>>>> First pass implementation of the "Tool Meister"
import time
import errno
import redis
import logging
from distutils.spawn import find_executable
from pathlib import Path


# Port number is "One Tool" in hex 0x17001
# FIXME: move to common area
redis_port = 17001

# Redis server configuration template for pbench's use
redis_conf_tmpl = """bind {hostnames}
daemonize yes
dir {tm_dir}
dbfilename pbench-redis.rdb
logfile {tm_dir}/redis.log
loglevel notice
pidfile {tm_dir}/redis_{redis_port:d}.pid
port {redis_port:d}
"""

# FIXME: this should be moved to a shared area
channel = "tool-meister-chan"

<<<<<<< HEAD
# Maximum time to wait for the Redis server to respond.
REDIS_MAX_WAIT = 60

=======
>>>>>>> First pass implementation of the "Tool Meister"

class ToolGroup(object):
    tg_prefix = "tools-v1"

    def __init__(self, group):
        self.group = group
        _pbench_run = os.environ["pbench_run"]
        self.tg_dir = Path(_pbench_run, f"{self.tg_prefix}-{self.group}").resolve(
            strict=True
        )
        if not self.tg_dir.is_dir():
            raise Exception(
                f"bad tool group, {group}: directory {self.tg_dir} does not exist"
            )

        # __trigger__
        try:
            with (self.tg_dir / "__trigger__").open("r") as fp:
                _trigger = fp.read()
        except OSError as ex:
            if ex.errno != errno.ENOENT:
                raise
            # Ignore missing trigger file
            self.trigger = None
        else:
            if len(_trigger) == 0:
                # Ignore empty trigger file contents
                self.trigger = None
            else:
                self.trigger = _trigger

        # toolnames - Dict with tool name as the key, dictionary with host
        # names and parameters for each host
        self.toolnames = {}
        # hostnames - Dict with host name as the key, dictionary with tool
        # names and parameters for each tool
        self.hostnames = {}
        self.labels = {}
        for hdirent in os.listdir(self.tg_dir):
            if hdirent == "__trigger__":
                # Ignore handled above
                continue
            if not (self.tg_dir / hdirent).is_dir():
                # Ignore wayward non-directory files
                continue
            # We assume this directory is a hostname.
            host = hdirent
            if host not in self.hostnames:
                self.hostnames[host] = {}
            for tdirent in os.listdir(self.tg_dir / host):
                if tdirent == "__label__":
                    with (self.tg_dir / host / tdirent).open("r") as fp:
                        self.labels[host] = fp.read()
                    continue
                if tdirent.endswith("__noinstall__"):
                    # FIXME: ignore "noinstall" for now, tools are going to be
                    # in containers so this does not make sense going forward.
                    continue
                tool = tdirent
                with (self.tg_dir / host / tool).open("r") as fp:
                    tool_opts = fp.read()
                if tool not in self.toolnames:
                    self.toolnames[tool] = {}
                self.toolnames[tool][host] = tool_opts

    def get_tools(self, host):
        """Given a target host, return a dictionary with the list of tool names
        as keys, and the values being their options for that host.
        """
        tools = dict()
        for tool, opts in self.toolnames.items():
<<<<<<< HEAD
            try:
                host_opts = opts[host]
            except KeyError:
                # This host does not have this tool registered, ignore.
                pass
            else:
                tools[tool] = host_opts
        return tools


def wait_for_subs(chan, expected_tms, logger):
    """wait_for_subs - Wait for the data sink and the proper number of TMs to
    register, and when they are all registered, return a dictionary of the
    data sink and tool meister(s) pids.
=======
            tools[tool] = opts[host]
        return tools


def wait_for_subs(redis_server, chan, expected_tms, logger):
    """Wait for the data sink and the proper number of TMs to register, and
    when they are all registered, then record them in the "tm-pids" key.
>>>>>>> First pass implementation of the "Tool Meister"
    """
    pids = dict()
    have_ds = False
    num_tms = 0
    for payload in chan:
        try:
            json_str = payload["data"].decode("utf-8")
        except Exception:
            logger.warning("data payload in message not UTF-8, '%r'", json_str)
            continue
        logger.debug('channel payload, "%r"', json_str)
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError:
            logger.warning("data payload in message not JSON, '%s'", json_str)
            continue
        # We expect the payload to look like:
        #   { "kind": "<ds|tm>",
        #     "hostname": "<hostname>",
        #     "pid": "<pid>"
        #   }
        # Where 'kind' is either 'ds' (data-sink) or 'tm' (tool-meister),
        # 'hostname' is the host name on which that entity is running, and
        # 'pid' is that entity's PID on that host.
        try:
            new_data = dict(
                kind=data["kind"], hostname=data["hostname"], pid=data["pid"]
            )
        except KeyError:
<<<<<<< HEAD
            logger.warning("unrecognized data payload in message, '%r'", data)
=======
            logger.warning("unrecognized data payload in message," " '%r'", data)
>>>>>>> First pass implementation of the "Tool Meister"
            continue
        else:
            if new_data["kind"] == "ds":
                pids["ds"] = new_data
                have_ds = True
            elif new_data["kind"] == "tm":
                if "tm" not in pids:
                    pids["tm"] = []
                pids["tm"].append(new_data)
                num_tms += 1
            else:
                logger.warning("unrecognized 'kind', in data payload '%r'", data)
                continue
        if have_ds and num_tms == expected_tms:
            break
<<<<<<< HEAD
    return pids


def kill_redis_server(pid_file):
    """kill_redis_server - given a redis server PID file, attempt to KILL the
    Redis server.

    Returns "1" if successfully KILL'd; "2" if it encounters an error reading
    the PID file; "3" if bad PID value; "4" if the Redis server PID does not
    exist; "5" if some kind of OSError is encountered; and "6" if some other
    exception was encountered while KILL'ing it.
    """
    try:
        with pid_file.open("r") as fp:
            raw_pid = fp.read()
    except Exception:
        # No "pid" to kill
        return 2
    else:
        try:
            pid = int(raw_pid)
        except Exception:
            # Bad pid value
            return 3
        try:
            os.kill(pid, signal.SIGKILL)
        except OSError as exc:
            if exc.errno == errno.ESRCH:
                # PID not found, ignore
                return 4
            else:
                # Some error encountered trying to KILL the process.
                return 5
        except Exception:
            # Some other error encountered trying to KILL the process.
            return 6
        else:
            # "successfully" KILL'd the give process.
            return 1
=======
    # Record our collected pids.
    redis_server.set("tm-pids", json.dumps(pids))
>>>>>>> First pass implementation of the "Tool Meister"


def main(argv):
    """Main program for the tool meister start.
    """
    _prog = Path(argv[0])
    _prog_dir = _prog.parent
    PROG = _prog.name
    logger = logging.getLogger(PROG)
    if os.environ.get("_PBENCH_TOOL_MEISTER_START_LOG_LEVEL") == "debug":
        log_level = logging.DEBUG
    else:
        log_level = logging.INFO
    logger.setLevel(log_level)
    sh = logging.StreamHandler()
    sh.setLevel(log_level)
    shf = logging.Formatter("%(message)s")
    sh.setFormatter(shf)
    logger.addHandler(sh)

    try:
        group = argv[1]
    except IndexError:
        group = "default"

    # 1. Load the tool group data given the tool group argument
    try:
        tool_group = ToolGroup(group)
    except Exception:
        logger.exception("failed to load tool group data")
        return 1

    try:
        benchmark_run_dir = os.environ["benchmark_run_dir"]
        hostname = os.environ["hostname"]
        full_hostname = os.environ["full_hostname"]
    except Exception:
        logger.exception("failed to fetch parameters from the environment")
        return 1
    else:
        tm_dir = Path(benchmark_run_dir, "tm")
        try:
            os.mkdir(tm_dir)
            os.chdir(tm_dir)
        except Exception:
<<<<<<< HEAD
            logger.exception("failed to create the local tool meister directory")
=======
            logger.exception("failed to create the local tool meister" " directory")
>>>>>>> First pass implementation of the "Tool Meister"
            return 1
    if not full_hostname or not hostname:
        logger.error(
            "ERROR - hostname ('%s') and full_hostname ('%s') environment"
            " variables are required",
            hostname,
            full_hostname,
        )
<<<<<<< HEAD
        return 1
=======
>>>>>>> First pass implementation of the "Tool Meister"
    if os.environ.get("_PBENCH_UNIT_TESTS"):
        # FIXME: this is an artifact of the unit test environment.
        hostnames = "localhost"
    else:
        hostnames = f"localhost {full_hostname}"
    params = {"hostnames": hostnames, "tm_dir": tm_dir, "redis_port": redis_port}

    # 2. Start the Redis Server (config of port from agent config)
    #   - the Redis Server is requested to create the PID file

    # Create the Redis Server pbench-specific configuration file
    redis_conf = tm_dir / "redis.conf"
<<<<<<< HEAD
    redis_pid = tm_dir / f"redis_{redis_port:d}.pid"
=======
>>>>>>> First pass implementation of the "Tool Meister"
    try:
        with redis_conf.open("w") as fp:
            fp.write(redis_conf_tmpl.format(**params))
    except Exception:
        logger.exception("failed to create redis server configuration")
        return 1
    # Start the Redis Server itself
    #   - FIXME: use podman to start a redis server container
    redis_srvr = "redis-server"
<<<<<<< HEAD
    redis_srvr_path = find_executable(redis_srvr)
=======
    redis_srvr_path = Path(os.path.sep, "usr", "bin", redis_srvr)
>>>>>>> First pass implementation of the "Tool Meister"
    logger.debug("starting redis server")
    try:
        retcode = os.spawnl(os.P_WAIT, redis_srvr_path, redis_srvr, redis_conf)
    except Exception:
        logger.exception("failed to create redis server, daemonized")
        return 1
    else:
        if retcode != 0:
            logger.error(
<<<<<<< HEAD
                "failed to create redis server, daemonized; return code: %d", retcode
=======
                "failed to create redis server, daemonized; return" " code: %d", retcode
>>>>>>> First pass implementation of the "Tool Meister"
            )
            return 1

    try:
<<<<<<< HEAD
        timeout = time.time() + REDIS_MAX_WAIT
        started_channel = "{}-start".format(channel)
        redis_connection_state = "connecting"
        redis_server = redis.Redis(host="localhost", port=redis_port, db=0)
        pubsub = redis_server.pubsub()
        while redis_connection_state == "connecting":
            try:
=======
        timeout = time.time() + 60
        started_channel = "{}-start".format(channel)
        redis_connection_state = "connecting"
        while redis_connection_state == "connecting":
            try:
                redis_server = redis.Redis(host="localhost", port=redis_port, db=0)
                pubsub = redis_server.pubsub()
>>>>>>> First pass implementation of the "Tool Meister"
                pubsub.subscribe(started_channel)
                chan = pubsub.listen()
                # Pull off first message which is an acknowledgement we have
                # successfully subscribed.
                resp = next(chan)
            except redis.exceptions.ConnectionError:
                if time.time() > timeout:
                    raise
<<<<<<< HEAD
                time.sleep(0.1)
=======
>>>>>>> First pass implementation of the "Tool Meister"
            else:
                redis_connection_state = "connected"
    except Exception as exc:
        logger.error(
            "Unable to connect to redis server, %s:%d: %r", "localhost", redis_port, exc
        )
<<<<<<< HEAD
        return kill_redis_server(redis_pid)
=======
        return 1
>>>>>>> First pass implementation of the "Tool Meister"
    else:
        assert resp["type"] == "subscribe", f"bad type: f{resp!r}"
        assert resp["pattern"] is None, f"bad pattern: {resp!r}"
        assert (
            resp["channel"].decode("utf-8") == started_channel
        ), f"bad channel: {resp!r}"
        assert resp["data"] == 1, f"bad data: {resp!r}"

    # 3. Start the tool-data-sink process
    #   - leave a PID file for the tool data sink process
    #   - FIXME: use podman to start a tool-data-sink container
    tds_param_key = "tds-{}".format(group)
    tds = dict(channel=channel, benchmark_run_dir=benchmark_run_dir)
    try:
<<<<<<< HEAD
        redis_server.set(tds_param_key, json.dumps(tds, sort_keys=True))
    except Exception:
        logger.exception(
            "failed to create tool data sink parameter key in redis server"
        )
        return kill_redis_server(redis_pid)
=======
        redis_server.set(tds_param_key, json.dumps(tds))
    except Exception:
        logger.exception(
            "failed to create tool-data-sink parameter key in" " redis server"
        )
        # FIXME: fetch redis-server PID file and kill it.
        return 1
>>>>>>> First pass implementation of the "Tool Meister"
    data_sink = "pbench-tool-data-sink"
    data_sink_path = _prog_dir / data_sink
    logger.debug("starting tool data sink")
    try:
        retcode = os.spawnl(
            os.P_WAIT,
            data_sink_path,
            data_sink,
            "localhost",
            str(redis_port),
            tds_param_key,
        )
    except Exception:
        logger.exception("failed to create pbench data sink, daemonized")
<<<<<<< HEAD
        return kill_redis_server(redis_pid)
    else:
        if retcode != 0:
            logger.error(
                "failed to create pbench data sink, daemonized; return code: %d",
                retcode,
            )
            return kill_redis_server(redis_pid)
=======
        return 1
    else:
        if retcode != 0:
            logger.error(
                "failed to create pbench data sink, daemonized;" " return code: %d",
                retcode,
            )
            return 1
>>>>>>> First pass implementation of the "Tool Meister"

    # 4. Start all the local and remote tool meister processes
    #   - leave a PID file on each local/remote host
    #   - FIXME: use podman on the remote hosts to start a tool meister
    #            container
    failures = 0
    successes = 0
    tool_meister_cmd = "pbench-tool-meister"
    tool_meister_cmd_path = _prog_dir / tool_meister_cmd
<<<<<<< HEAD
    ssh_cmd = "ssh"
    ssh_path = find_executable(ssh_cmd)
=======
    ssh_path = find_executable("ssh")
    ssh_cmd = "ssh"
>>>>>>> First pass implementation of the "Tool Meister"
    args = [
        ssh_cmd,
        "<host replace me>",
        tool_meister_cmd,
        full_hostname,
        str(redis_port),
        "<tm param key>",
    ]
    ssh_pids = []
    for host in tool_group.hostnames.keys():
        tools = tool_group.get_tools(host)
        if host == full_hostname:
            _controller = full_hostname
        else:
            _controller = (
                "localhost" if os.environ.get("_PBENCH_UNIT_TESTS") else full_hostname
            )
        tm = dict(
            benchmark_run_dir=benchmark_run_dir,
            channel=channel,
            controller=_controller,
            group=group,
            hostname=host,
            tools=tools,
        )
        tm_param_key = "tm-{}-{}".format(group, host)
        try:
<<<<<<< HEAD
            redis_server.set(tm_param_key, json.dumps(tm, sort_keys=True))
        except Exception:
            logger.exception(
                "failed to create tool meister parameter key in redis server"
            )
            return kill_redis_server(redis_pid)
        if host == full_hostname:
            logger.debug("starting localhost tool meister")
=======
            redis_server.set(tm_param_key, json.dumps(tm))
        except Exception:
            logger.exception(
                "failed to create tool-data-sink parameter key" " in redis server"
            )
            # FIXME: fetch redis-server PID file and kill it.
            return 1
        if host == full_hostname:
            logger.debug("starting locolhost tool meister")
>>>>>>> First pass implementation of the "Tool Meister"
            try:
                retcode = os.spawnl(
                    os.P_WAIT,
                    tool_meister_cmd_path,
                    tool_meister_cmd,
                    "localhost",
                    str(redis_port),
                    tm_param_key,
                )
            except Exception:
<<<<<<< HEAD
                logger.exception("failed to create localhost tool meister, daemonized")
=======
                logger.exception("failed to create pbench tool meister," " daemonized")
>>>>>>> First pass implementation of the "Tool Meister"
                failures += 1
            else:
                if retcode == 0:
                    successes += 1
                else:
                    logger.error(
<<<<<<< HEAD
                        "failed to create localhost tool meister,"
=======
                        "failed to create pbench tool meister,"
>>>>>>> First pass implementation of the "Tool Meister"
                        " daemonized; return code: %d",
                        retcode,
                    )
                    failures += 1
<<<<<<< HEAD
=======

>>>>>>> First pass implementation of the "Tool Meister"
            continue
        args[1] = host
        args[5] = tm_param_key
        logger.debug(
            "starting remote tool meister, ssh_path=%r args=%r", ssh_path, args
        )
<<<<<<< HEAD
        # FIXME: should we consider using Ansible instead?
=======
        # FIXME: here we should consider using Ansible instead
>>>>>>> First pass implementation of the "Tool Meister"
        try:
            pid = os.spawnv(os.P_NOWAIT, ssh_path, args)
        except Exception:
            logger.exception(
<<<<<<< HEAD
                "failed to create a tool meister instance for host %s", host
=======
                "failed to create a tool meister instance for" " host %s", host
>>>>>>> First pass implementation of the "Tool Meister"
            )
            failures += 1
        else:
            ssh_pids.append((pid, host))
            successes += 1
<<<<<<< HEAD

    if failures > 0:
        return kill_redis_server(redis_pid)

=======
>>>>>>> First pass implementation of the "Tool Meister"
    # Wait for all the SSH pids to complete.
    for pid, host in ssh_pids:
        try:
            exit_pid, _exit_status = os.waitpid(pid, 0)
        except OSError:
<<<<<<< HEAD
            failures += 1
            successes -= 1
            logger.exception(
                "failed to create a tool meister instance for host %s", host
            )
        else:
            exit_status = os.WEXITSTATUS(_exit_status)
            if pid != exit_pid:
                failures += 1
                successes -= 1
=======
            logger.exception(
                "failed to create a tool meister instance for" " host %s", host
            )
            failures += 1
            successes -= 1
        else:
            exit_status = os.WEXITSTATUS(_exit_status)
            if pid != exit_pid:
>>>>>>> First pass implementation of the "Tool Meister"
                logger.error(
                    "INTERNAL ERROR: os.waitpid(%d, 0) returned (%d, %d [%0X])",
                    pid,
                    exit_pid,
                    exit_status,
                    _exit_status,
                )
            else:
                if exit_status != 0:
                    failures += 1
                    successes -= 1
                    logger.error(
<<<<<<< HEAD
                        "failed to start tool meister on remote host '%s'"
=======
                        "failed to start tool-meister on remote host '%s'"
>>>>>>> First pass implementation of the "Tool Meister"
                        " (pid %d), exit status: %d [%0X]",
                        host,
                        pid,
                        exit_status,
                        _exit_status,
                    )

<<<<<<< HEAD
    if failures > 0:
        logger.info("terminating tool meister startup due to failures")
        terminate_msg = dict(state="terminate", group=group, directory=None)
        try:
            ret = redis_server.publish(
                channel, json.dumps(terminate_msg, sort_keys=True)
            )
=======
    # If any successes, then we need to wait for them to show up as
    # subscribers.
    logger.debug("waiting for subs")
    wait_for_subs(redis_server, chan, successes, logger)

    # For any failures, just terminate early.
    if failures > 0:
        logger.info("terminating localhost:%d due to failures", redis_port)
        terminate_msg = dict(state="terminate", group=group, directory=None)
        try:
            ret = redis_server.publish(channel, json.dumps(terminate_msg))
>>>>>>> First pass implementation of the "Tool Meister"
        except Exception:
            logger.exception("Failed to publish terminate message")
        else:
            logger.debug("publish() = %r", ret)
<<<<<<< HEAD
        ret_val = kill_redis_server(redis_pid)
    elif successes > 0:
        # If any successes, then we need to wait for them to show up as
        # subscribers.
        logger.debug(
            "waiting for all successfully spawned SSH processes"
            " to show up as subscribers"
        )
        pids = wait_for_subs(chan, successes, logger)
        # Record our collected pids.
        try:
            redis_server.set("tm-pids", json.dumps(pids, sort_keys=True))
        except Exception:
            logger.exception("failed to set tool meister pids object")
            ret_val = kill_redis_server(redis_pid)
        else:
            ret_val = 0
    else:
        logger.warning(
            "unable to successfully start any tool meisters,"
            " but encountered no failures either: terminating"
        )
        ret_val = kill_redis_server(redis_pid)
    return ret_val
=======
        # FIXME: kill redis server PID

    return 1 if failures > 0 else 0
>>>>>>> First pass implementation of the "Tool Meister"


if __name__ == "__main__":
    status = main(sys.argv)
    sys.exit(status)
